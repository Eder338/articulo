{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTAR LIBRERÍAS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPORTANDO LIBRERÍAS...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Para leer archivos SPSS\n",
        "try:\n",
        "    import pyreadstat\n",
        "    print(\"✓ pyreadstat importado correctamente\")\n",
        "except ImportError:\n",
        "    print(\"❌ ERROR: pyreadstat no está instalado\")\n",
        "    print(\"   Instalar con: pip install pyreadstat\")\n",
        "    exit()\n",
        "\n",
        "# Preprocesamiento\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Modelos de clasificación\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Métricas de evaluación\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "# Configuración de visualización\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"Set2\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"✓ Todas las librerías importadas correctamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhX6_wXtsT05",
        "outputId": "d1876eaa-e2a5-439a-e843-de6342d7b5da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "IMPORTANDO LIBRERÍAS...\n",
            "================================================================================\n",
            "✓ pyreadstat importado correctamente\n",
            "✓ Todas las librerías importadas correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyreadstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2A-2_YFsd5Z",
        "outputId": "277a253d-e11c-482a-8b62-650722efc53b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyreadstat\n",
            "  Downloading pyreadstat-1.3.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: narwhals>=2.0 in /usr/local/lib/python3.12/dist-packages (from pyreadstat) (2.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pyreadstat) (2.0.2)\n",
            "Downloading pyreadstat-1.3.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreadstat\n",
            "Successfully installed pyreadstat-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 1: CARGAR DATOS DESDE SPSS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 1: CARGANDO DATOS DESDE ARCHIVO SPSS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    # Cargar archivo .sav de SPSS\n",
        "    df, meta = pyreadstat.read_sav('CSALUD08_2024.sav')\n",
        "    print(f\"✓ Datos cargados exitosamente\")\n",
        "    print(f\"  - Dimensiones: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ ERROR: No se encontró el archivo 'CSALUD08_2024.sav'\")\n",
        "    print(\"   Asegúrate de que el archivo esté en la misma carpeta que este script\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR al cargar datos: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\n✓ Primeras 5 filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\n✓ Columnas disponibles ({len(df.columns)}):\")\n",
        "print(list(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SinSmqdgsjWU",
        "outputId": "78e74224-0a62-4d12-e6aa-fb7ad162a1b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 1: CARGANDO DATOS DESDE ARCHIVO SPSS\n",
            "================================================================================\n",
            "✓ Datos cargados exitosamente\n",
            "  - Dimensiones: 41,309 filas x 53 columnas\n",
            "\n",
            "✓ Primeras 5 filas del dataset:\n",
            "      ID1             HHID  QHCLUSTER  QHNUMBER  QHHOME  QS800  QS801  QS802  \\\n",
            "0  2024.0        325503101     3255.0      31.0     1.0    NaN    3.0    2.0   \n",
            "1  2024.0        325504701     3255.0      47.0     1.0    NaN    3.0    2.0   \n",
            "2  2024.0        325504701     3255.0      47.0     1.0    NaN    4.0    2.0   \n",
            "3  2024.0        325505001     3255.0      50.0     1.0    NaN    3.0    1.0   \n",
            "4  2024.0        325505301     3255.0      53.0     1.0    NaN    2.0    1.0   \n",
            "\n",
            "   QS802V  QS802A  ...  QS832  QS833  QS834  QS835  QS836  QS837  QS838  \\\n",
            "0     1.0     1.0  ...    NaN    NaN    NaN    NaN    NaN    NaN          \n",
            "1     1.0     1.0  ...    2.0    1.0    1.0    1.0    2.0    2.0      C   \n",
            "2     1.0     1.0  ...    NaN    NaN    NaN    NaN    NaN    NaN          \n",
            "3     1.0     1.0  ...    NaN    NaN    NaN    NaN    NaN    NaN          \n",
            "4     1.0     1.0  ...    1.0    1.0    1.0    1.0    1.0    2.0      C   \n",
            "\n",
            "   QS840A  QS840B      Pesomen12  \n",
            "0     1.0     1.0  110101.308863  \n",
            "1     1.0     1.0  266556.053902  \n",
            "2     1.0     1.0  110101.308863  \n",
            "3     1.0     4.0  110101.308863  \n",
            "4     1.0     1.0  298244.909243  \n",
            "\n",
            "[5 rows x 53 columns]\n",
            "\n",
            "✓ Columnas disponibles (53):\n",
            "['ID1', 'HHID', 'QHCLUSTER', 'QHNUMBER', 'QHHOME', 'QS800', 'QS801', 'QS802', 'QS802V', 'QS802A', 'QS802CD', 'QS802CM', 'QS802CA', 'QS802D', 'QS803', 'QS804U', 'QS804C', 'QS805', 'QS806', 'QS807', 'QS809', 'QS810', 'QS811', 'QS812U', 'QS812C', 'QS813', 'QS814', 'QS817', 'QS818U', 'QS818C', 'QS819', 'QS820', 'QS821', 'QS822U', 'QS822C', 'QS823', 'QS824', 'QS825', 'QS826', 'QS827', 'QS828', 'QS829', 'QS831', 'QS832', 'QS833', 'QS834', 'QS835', 'QS836', 'QS837', 'QS838', 'QS840A', 'QS840B', 'Pesomen12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 2: LIMPIEZA DE DATOS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 2: LIMPIEZA DE DATOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 2.1 Valores perdidos iniciales\n",
        "print(\"\\n2.1 Análisis de valores perdidos:\")\n",
        "missing_before = df.isnull().sum().sum()\n",
        "print(f\"  Total de valores perdidos: {missing_before:,}\")\n",
        "\n",
        "# 2.2 Crear copia del dataframe\n",
        "df_clean = df.copy()\n",
        "\n",
        "# 2.3 Filtrar variable objetivo QS810\n",
        "print(\"\\n2.2 Filtrando variable objetivo (QS810)...\")\n",
        "print(f\"  Registros antes: {len(df_clean):,}\")\n",
        "print(f\"  Distribución original:\")\n",
        "print(df_clean['QS810'].value_counts(dropna=False))\n",
        "\n",
        "# Mantener solo respuestas válidas (1=Sí, 2=No)\n",
        "df_clean = df_clean[df_clean['QS810'].isin([1, 2])].copy()\n",
        "print(f\"  Registros después: {len(df_clean):,}\")\n",
        "print(f\"  Registros eliminados: {len(df) - len(df_clean):,}\")\n",
        "\n",
        "# Recodificar variable objetivo (1=Sí->1, 2=No->0)\n",
        "df_clean['QS810'] = df_clean['QS810'].map({1: 1, 2: 0})\n",
        "\n",
        "print(f\"\\n  Variable objetivo recodificada:\")\n",
        "print(df_clean['QS810'].value_counts())\n",
        "print(f\"  Proporción:\")\n",
        "print(df_clean['QS810'].value_counts(normalize=True).round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JENg6jMqswJu",
        "outputId": "13584309-02da-4de0-9f53-d7e2b2f6a2b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 2: LIMPIEZA DE DATOS\n",
            "================================================================================\n",
            "\n",
            "2.1 Análisis de valores perdidos:\n",
            "  Total de valores perdidos: 891,450\n",
            "\n",
            "2.2 Filtrando variable objetivo (QS810)...\n",
            "  Registros antes: 41,309\n",
            "  Distribución original:\n",
            "QS810\n",
            "1.0    25019\n",
            "NaN    10155\n",
            "2.0     6119\n",
            "8.0       16\n",
            "Name: count, dtype: int64\n",
            "  Registros después: 31,138\n",
            "  Registros eliminados: 10,171\n",
            "\n",
            "  Variable objetivo recodificada:\n",
            "QS810\n",
            "1    25019\n",
            "0     6119\n",
            "Name: count, dtype: int64\n",
            "  Proporción:\n",
            "QS810\n",
            "1    0.803\n",
            "0    0.197\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 2.5: MANEJO DE VARIABLES CATEGÓRICAS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 2.5: PROCESAMIENTO DE VARIABLES CATEGÓRICAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 2.5.1 Variables binarias (1=Sí, 2=No) -> (1, 0)\n",
        "print(\"\\n2.5.1 Recodificando variables binarias...\")\n",
        "\n",
        "variables_binarias = {\n",
        "    'QS803': 'Atendido por odontólogo',\n",
        "    'QS806': 'Recibió información higiene bucal',\n",
        "    'QS809': 'Usa cepillo dental',\n",
        "    'QS814': 'Usa crema dental',\n",
        "    'QS817': 'Evaluaron vista',\n",
        "    'QS820': 'Problema de visión',\n",
        "    'QS828': 'Ve TV/PC muy cerca',\n",
        "    'QS833': 'Asistió escuela',\n",
        "    'QS836': 'Confianza con profesor'\n",
        "}\n",
        "\n",
        "for var, desc in variables_binarias.items():\n",
        "    if var in df_clean.columns:\n",
        "        # Reemplazar códigos especiales con NaN\n",
        "        df_clean.loc[df_clean[var].isin([8, 9]), var] = np.nan\n",
        "\n",
        "        # Recodificar (1->1, 2->0)\n",
        "        if df_clean[var].dropna().isin([1, 2]).any():\n",
        "            df_clean[var] = df_clean[var].map({1: 1, 2: 0})\n",
        "            print(f\"  ✓ {var}: {desc}\")\n",
        "\n",
        "# 2.5.2 Variables ordinales\n",
        "print(\"\\n2.5.2 Procesando variables ordinales...\")\n",
        "\n",
        "# QS811: Frecuencia de cepillado (1-4)\n",
        "if 'QS811' in df_clean.columns:\n",
        "    print(f\"  ✓ QS811: Frecuencia cepillado (valores: {sorted(df_clean['QS811'].dropna().unique())})\")\n",
        "\n",
        "# QS834 y QS835: Frecuencia de golpes (1=Nunca, 2=Rara vez, 3=A veces, 4=A menudo)\n",
        "for var in ['QS834', 'QS835']:\n",
        "    if var in df_clean.columns:\n",
        "        df_clean.loc[df_clean[var] == 8, var] = np.nan\n",
        "        print(f\"  ✓ {var}: Limpiado\")\n",
        "\n",
        "# 2.5.3 Variables categóricas -> Crear variables derivadas\n",
        "print(\"\\n2.5.3 Creando variables derivadas...\")\n",
        "\n",
        "# QS840B: Concentración de flúor -> Variable binaria\n",
        "if 'QS840B' in df_clean.columns:\n",
        "    # 1=1000ppm+, 2=601-999ppm, 3=<=600ppm, 4-9=Otros\n",
        "    df_clean['fluor_adecuado'] = df_clean['QS840B'].apply(\n",
        "        lambda x: 1 if x == 1 else (0 if x in [2, 3] else np.nan)\n",
        "    )\n",
        "    print(f\"  ✓ Creada 'fluor_adecuado': {df_clean['fluor_adecuado'].value_counts().to_dict()}\")\n",
        "\n",
        "# QS807: Fuente de información -> Variables dummy\n",
        "if 'QS807' in df_clean.columns:\n",
        "    df_clean['info_minsa'] = df_clean['QS807'].astype(str).str.contains('A', na=False).astype(int)\n",
        "    df_clean['info_escuela'] = df_clean['QS807'].astype(str).str.contains('I', na=False).astype(int)\n",
        "    df_clean['info_familia'] = df_clean['QS807'].astype(str).str.contains('J', na=False).astype(int)\n",
        "    df_clean['info_medios'] = df_clean['QS807'].astype(str).str.contains('H', na=False).astype(int)\n",
        "    print(f\"  ✓ Creadas variables dummy de fuentes de información\")\n",
        "\n",
        "# Quintil socioeconómico (si existe Pesomen12)\n",
        "if 'Pesomen12' in df_clean.columns:\n",
        "    try:\n",
        "        df_clean['quintil_peso'] = pd.qcut(\n",
        "            df_clean['Pesomen12'],\n",
        "            q=5,\n",
        "            labels=[1, 2, 3, 4, 5],\n",
        "            duplicates='drop'\n",
        "        ).astype(float)\n",
        "        print(f\"  ✓ Creada 'quintil_peso' (nivel socioeconómico)\")\n",
        "    except:\n",
        "        print(f\"  ⚠ No se pudo crear quintil_peso\")\n",
        "\n",
        "print(f\"\\n✓ Variables procesadas. Total de columnas: {df_clean.shape[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8eskKultMp1",
        "outputId": "f0c38ef1-76bb-4918-f10b-67b8e25a6633"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 2.5: PROCESAMIENTO DE VARIABLES CATEGÓRICAS\n",
            "================================================================================\n",
            "\n",
            "2.5.1 Recodificando variables binarias...\n",
            "  ✓ QS803: Atendido por odontólogo\n",
            "  ✓ QS806: Recibió información higiene bucal\n",
            "  ✓ QS809: Usa cepillo dental\n",
            "  ✓ QS814: Usa crema dental\n",
            "  ✓ QS817: Evaluaron vista\n",
            "  ✓ QS820: Problema de visión\n",
            "  ✓ QS828: Ve TV/PC muy cerca\n",
            "  ✓ QS833: Asistió escuela\n",
            "  ✓ QS836: Confianza con profesor\n",
            "\n",
            "2.5.2 Procesando variables ordinales...\n",
            "  ✓ QS811: Frecuencia cepillado (valores: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0)])\n",
            "  ✓ QS834: Limpiado\n",
            "  ✓ QS835: Limpiado\n",
            "\n",
            "2.5.3 Creando variables derivadas...\n",
            "  ✓ Creada 'fluor_adecuado': {1.0: 18674, 0.0: 2058}\n",
            "  ✓ Creadas variables dummy de fuentes de información\n",
            "  ✓ Creada 'quintil_peso' (nivel socioeconómico)\n",
            "\n",
            "✓ Variables procesadas. Total de columnas: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 3: SELECCIÓN DE VARIABLES\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 3: SELECCIÓN DE VARIABLES PREDICTORAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Lista de variables predictoras\n",
        "variables_predictoras = [\n",
        "    # Demográficas\n",
        "    'QS802D',           # Edad del niño\n",
        "\n",
        "    # Salud bucal\n",
        "    'QS803',            # Atendido por odontólogo\n",
        "    'QS806',            # Recibió información\n",
        "    'QS809',            # Usa cepillo\n",
        "    'QS811',            # Frecuencia cepillado\n",
        "    'QS814',            # Usa crema dental\n",
        "    'fluor_adecuado',   # Flúor adecuado\n",
        "\n",
        "    # Información\n",
        "    'info_minsa',\n",
        "    'info_escuela',\n",
        "    'info_familia',\n",
        "    'info_medios',\n",
        "\n",
        "    # Salud ocular/mental\n",
        "    'QS828',            # Ve TV muy cerca\n",
        "    'QS834',            # Golpeado por profesor\n",
        "    'QS835',            # Golpeado por estudiante\n",
        "    'QS836',            # Confianza profesor\n",
        "\n",
        "    # Socioeconómico\n",
        "    'Pesomen12',        # Factor ponderación\n",
        "    'quintil_peso'      # Quintil socioeconómico\n",
        "]\n",
        "\n",
        "# Filtrar variables disponibles\n",
        "variables_disponibles = [v for v in variables_predictoras if v in df_clean.columns]\n",
        "variables_faltantes = [v for v in variables_predictoras if v not in df_clean.columns]\n",
        "\n",
        "print(f\"\\n✓ Variables disponibles: {len(variables_disponibles)}\")\n",
        "for i, var in enumerate(variables_disponibles, 1):\n",
        "    print(f\"  {i:2d}. {var}\")\n",
        "\n",
        "if variables_faltantes:\n",
        "    print(f\"\\n⚠ Variables no disponibles: {len(variables_faltantes)}\")\n",
        "    for var in variables_faltantes:\n",
        "        print(f\"  - {var}\")\n",
        "\n",
        "# Crear dataset final\n",
        "columnas_finales = variables_disponibles + ['QS810']\n",
        "df_final = df_clean[columnas_finales].copy()\n",
        "\n",
        "print(f\"\\n✓ Dataset final: {df_final.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq4CwnmGttWV",
        "outputId": "a3956848-f9f7-4d98-b86e-762b0dcd8e71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 3: SELECCIÓN DE VARIABLES PREDICTORAS\n",
            "================================================================================\n",
            "\n",
            "✓ Variables disponibles: 17\n",
            "   1. QS802D\n",
            "   2. QS803\n",
            "   3. QS806\n",
            "   4. QS809\n",
            "   5. QS811\n",
            "   6. QS814\n",
            "   7. fluor_adecuado\n",
            "   8. info_minsa\n",
            "   9. info_escuela\n",
            "  10. info_familia\n",
            "  11. info_medios\n",
            "  12. QS828\n",
            "  13. QS834\n",
            "  14. QS835\n",
            "  15. QS836\n",
            "  16. Pesomen12\n",
            "  17. quintil_peso\n",
            "\n",
            "✓ Dataset final: (31138, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 3.5: IMPUTACIÓN DE VALORES PERDIDOS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 3.5: IMPUTACIÓN DE VALORES PERDIDOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nValores perdidos por variable:\")\n",
        "missing_counts = df_final.isnull().sum()\n",
        "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
        "if len(missing_counts) > 0:\n",
        "    for var, count in missing_counts.items():\n",
        "        pct = (count / len(df_final)) * 100\n",
        "        print(f\"  {var:<20} {count:>6} ({pct:>5.1f}%)\")\n",
        "\n",
        "    # Imputar con mediana para variables numéricas\n",
        "    print(\"\\nImputando valores perdidos con mediana...\")\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "    numeric_cols = [col for col in variables_disponibles if col in df_final.columns]\n",
        "    df_final[numeric_cols] = imputer.fit_transform(df_final[numeric_cols])\n",
        "\n",
        "    print(f\"✓ Valores imputados\")\n",
        "else:\n",
        "    print(\"✓ No hay valores perdidos\")\n",
        "\n",
        "print(f\"\\n✓ Valores perdidos finales: {df_final.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e0XUUfluMl5",
        "outputId": "af2cbba7-c9c5-4336-aab6-f94b6cda18c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 3.5: IMPUTACIÓN DE VALORES PERDIDOS\n",
            "================================================================================\n",
            "\n",
            "Valores perdidos por variable:\n",
            "  QS836                 19167 ( 61.6%)\n",
            "  QS834                 18805 ( 60.4%)\n",
            "  QS835                 18803 ( 60.4%)\n",
            "  fluor_adecuado        10406 ( 33.4%)\n",
            "  QS806                 10212 ( 32.8%)\n",
            "  QS828                  7011 ( 22.5%)\n",
            "  QS811                  6119 ( 19.7%)\n",
            "\n",
            "Imputando valores perdidos con mediana...\n",
            "✓ Valores imputados\n",
            "\n",
            "✓ Valores perdidos finales: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 4: SEPARAR X E Y\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 4: SEPARACIÓN DE CARACTERÍSTICAS Y OBJETIVO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X = df_final.drop('QS810', axis=1)\n",
        "y = df_final['QS810']\n",
        "\n",
        "print(f\"\\n✓ Características (X): {X.shape}\")\n",
        "print(f\"  Columnas: {list(X.columns)}\")\n",
        "\n",
        "print(f\"\\n✓ Variable objetivo (y): {y.shape}\")\n",
        "print(f\"  Distribución de clases:\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\n  Proporción:\")\n",
        "print(y.value_counts(normalize=True).round(3))\n",
        "\n",
        "# Verificar balance\n",
        "balance = y.value_counts(normalize=True).min()\n",
        "if balance < 0.3:\n",
        "    print(\"\\n⚠ ADVERTENCIA: Clases desbalanceadas\")\n",
        "else:\n",
        "    print(\"\\n✓ Clases balanceadas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX9y6toVuVoO",
        "outputId": "4cff8871-75b1-4b7d-e104-3642df4a15ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 4: SEPARACIÓN DE CARACTERÍSTICAS Y OBJETIVO\n",
            "================================================================================\n",
            "\n",
            "✓ Características (X): (31138, 17)\n",
            "  Columnas: ['QS802D', 'QS803', 'QS806', 'QS809', 'QS811', 'QS814', 'fluor_adecuado', 'info_minsa', 'info_escuela', 'info_familia', 'info_medios', 'QS828', 'QS834', 'QS835', 'QS836', 'Pesomen12', 'quintil_peso']\n",
            "\n",
            "✓ Variable objetivo (y): (31138,)\n",
            "  Distribución de clases:\n",
            "QS810\n",
            "1    25019\n",
            "0     6119\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Proporción:\n",
            "QS810\n",
            "1    0.803\n",
            "0    0.197\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "⚠ ADVERTENCIA: Clases desbalanceadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 5: DIVISIÓN TRAIN/TEST\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 5: DIVISIÓN TRAIN/TEST (80/20)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ División completada:\")\n",
        "print(f\"  Entrenamiento: {X_train.shape[0]:,} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"  Prueba:        {X_test.shape[0]:,} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n✓ Distribución en entrenamiento:\")\n",
        "print(y_train.value_counts(normalize=True).round(3))\n",
        "\n",
        "print(f\"\\n✓ Distribución en prueba:\")\n",
        "print(y_test.value_counts(normalize=True).round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZYiHmDTuZyv",
        "outputId": "6e06205a-420e-4253-cb60-e24e720ef3fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 5: DIVISIÓN TRAIN/TEST (80/20)\n",
            "================================================================================\n",
            "\n",
            "✓ División completada:\n",
            "  Entrenamiento: 24,910 muestras (80.0%)\n",
            "  Prueba:        6,228 muestras (20.0%)\n",
            "\n",
            "✓ Distribución en entrenamiento:\n",
            "QS810\n",
            "1    0.803\n",
            "0    0.197\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "✓ Distribución en prueba:\n",
            "QS810\n",
            "1    0.803\n",
            "0    0.197\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 6: ESCALAMIENTO/NORMALIZACIÓN\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 6: ESCALAMIENTO CON STANDARDSCALER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convertir de vuelta a DataFrame\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
        "\n",
        "print(f\"\\n✓ Datos escalados\")\n",
        "print(f\"\\nEstadísticas después del escalamiento (primeras 5 variables):\")\n",
        "print(X_train_scaled.describe().loc[['mean', 'std']].iloc[:, :5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyOdYTGzuiWR",
        "outputId": "148275b2-01f5-46f3-f3d5-0a84cd94da87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 6: ESCALAMIENTO CON STANDARDSCALER\n",
            "================================================================================\n",
            "\n",
            "✓ Datos escalados\n",
            "\n",
            "Estadísticas después del escalamiento (primeras 5 variables):\n",
            "            QS802D         QS803         QS806  QS809         QS811\n",
            "mean -1.537465e-16  1.257926e-16 -1.768513e-17    0.0  7.648104e-17\n",
            "std   1.000020e+00  1.000020e+00  1.000020e+00    0.0  1.000020e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN AUXILIAR: EVALUAR MODELO CON GRÁFICOS\n",
        "# =============================================================================\n",
        "def evaluar_modelo(nombre_modelo, modelo, X_train, X_test, y_train, y_test, cv=5, numero_modelo=1):\n",
        "    \"\"\"Evalúa un modelo de clasificación de manera exhaustiva con visualizaciones\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EVALUANDO: {nombre_modelo}\")\n",
        "    print('='*80)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Probabilidades\n",
        "    try:\n",
        "        y_pred_proba = modelo.predict_proba(X_test)[:, 1]\n",
        "        tiene_proba = True\n",
        "    except:\n",
        "        y_pred_proba = None\n",
        "        tiene_proba = False\n",
        "\n",
        "    # Métricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    if tiene_proba:\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    else:\n",
        "        roc_auc = None\n",
        "\n",
        "    # Validación cruzada\n",
        "    cv_scores = cross_val_score(\n",
        "        modelo, X_train, y_train,\n",
        "        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n",
        "        scoring='accuracy'\n",
        "    )\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(\"MÉTRICAS EN CONJUNTO DE PRUEBA:\")\n",
        "    print('─'*80)\n",
        "    print(f\"  Accuracy:     {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"  Precision:    {precision:.4f} ({precision*100:.2f}%)\")\n",
        "    print(f\"  Recall:       {recall:.4f} ({recall*100:.2f}%)\")\n",
        "    print(f\"  F1-Score:     {f1:.4f} ({f1*100:.2f}%)\")\n",
        "    if roc_auc:\n",
        "        print(f\"  ROC-AUC:      {roc_auc:.4f} ({roc_auc*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(\"VALIDACIÓN CRUZADA (5-FOLD):\")\n",
        "    print('─'*80)\n",
        "    print(f\"  Media:        {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "    print(f\"  Rango:        [{cv_scores.min():.4f}, {cv_scores.max():.4f}]\")\n",
        "\n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(\"MATRIZ DE CONFUSIÓN:\")\n",
        "    print('─'*80)\n",
        "    print(f\"\\n{cm}\")\n",
        "    print(f\"\\n  VN: {cm[0,0]:>6}  |  FP: {cm[0,1]:>6}\")\n",
        "    print(f\"  FN: {cm[1,0]:>6}  |  VP: {cm[1,1]:>6}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # GENERAR GRÁFICOS ESPECÍFICOS PARA ESTE MODELO\n",
        "    # =========================================================================\n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(\"GENERANDO GRÁFICOS...\")\n",
        "    print('─'*80)\n",
        "\n",
        "    # Limpiar nombre para archivo\n",
        "    nombre_archivo = nombre_modelo.replace(' ', '_').replace('/', '_')\n",
        "\n",
        "    # FIGURA COMPLETA: 2x2 grid\n",
        "    fig = plt.figure(figsize=(16, 12))\n",
        "    fig.suptitle(f'{nombre_modelo} - Análisis Completo', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # ----------- SUBPLOT 1: Matriz de Confusión -----------\n",
        "    ax1 = plt.subplot(2, 2, 1)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['No cepilla', 'Sí cepilla'],\n",
        "                yticklabels=['No cepilla', 'Sí cepilla'],\n",
        "                ax=ax1, annot_kws={'size': 14, 'weight': 'bold'})\n",
        "    ax1.set_xlabel('Predicción', fontsize=11, fontweight='bold')\n",
        "    ax1.set_ylabel('Valor Real', fontsize=11, fontweight='bold')\n",
        "    ax1.set_title('Matriz de Confusión', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Agregar texto con interpretación\n",
        "    total = cm.sum()\n",
        "    correctos = cm[0,0] + cm[1,1]\n",
        "    ax1.text(0.5, -0.25, f'Accuracy: {correctos}/{total} ({accuracy*100:.1f}%)',\n",
        "             transform=ax1.transAxes, ha='center', fontsize=10,\n",
        "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
        "\n",
        "    # ----------- SUBPLOT 2: Barras de Métricas -----------\n",
        "    ax2 = plt.subplot(2, 2, 2)\n",
        "    metricas_valores = [accuracy, precision, recall, f1]\n",
        "    metricas_nombres = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    colores = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
        "\n",
        "    barras = ax2.bar(metricas_nombres, metricas_valores, color=colores, alpha=0.7, edgecolor='black')\n",
        "    ax2.set_ylim([0, 1])\n",
        "    ax2.set_ylabel('Valor', fontsize=11, fontweight='bold')\n",
        "    ax2.set_title('Métricas de Evaluación', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Añadir valores sobre las barras\n",
        "    for i, (bar, val) in enumerate(zip(barras, metricas_valores)):\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # ----------- SUBPLOT 3: Curva ROC -----------\n",
        "    ax3 = plt.subplot(2, 2, 3)\n",
        "    if tiene_proba:\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "        ax3.plot(fpr, tpr, linewidth=2.5, label=f'ROC (AUC={roc_auc:.3f})', color='#e74c3c')\n",
        "        ax3.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Aleatorio (AUC=0.500)')\n",
        "        ax3.fill_between(fpr, tpr, alpha=0.2, color='#e74c3c')\n",
        "        ax3.set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=11, fontweight='bold')\n",
        "        ax3.set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=11, fontweight='bold')\n",
        "        ax3.set_title('Curva ROC', fontsize=12, fontweight='bold')\n",
        "        ax3.legend(loc='lower right', fontsize=10)\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "\n",
        "        # Marcar punto óptimo\n",
        "        optimal_idx = np.argmax(tpr - fpr)\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "        ax3.plot(fpr[optimal_idx], tpr[optimal_idx], 'go', markersize=10,\n",
        "                label=f'Óptimo (umbral={optimal_threshold:.2f})')\n",
        "        ax3.legend(loc='lower right', fontsize=9)\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'No disponible\\n(modelo sin probabilidades)',\n",
        "                ha='center', va='center', fontsize=12, transform=ax3.transAxes)\n",
        "        ax3.set_title('Curva ROC', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # ----------- SUBPLOT 4: Validación Cruzada -----------\n",
        "    ax4 = plt.subplot(2, 2, 4)\n",
        "\n",
        "    # Boxplot de CV scores\n",
        "    bp = ax4.boxplot([cv_scores], widths=0.5, patch_artist=True,\n",
        "                     boxprops=dict(facecolor='lightgreen', alpha=0.7),\n",
        "                     medianprops=dict(color='red', linewidth=2),\n",
        "                     whiskerprops=dict(linewidth=1.5),\n",
        "                     capprops=dict(linewidth=1.5))\n",
        "\n",
        "    # Scatter plot de los scores individuales\n",
        "    ax4.scatter([1]*len(cv_scores), cv_scores, color='darkgreen', s=100,\n",
        "               zorder=3, alpha=0.6, edgecolors='black')\n",
        "\n",
        "    ax4.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
        "    ax4.set_title('Validación Cruzada (5-Fold)', fontsize=12, fontweight='bold')\n",
        "    ax4.set_xticklabels(['CV Scores'])\n",
        "    ax4.grid(axis='y', alpha=0.3)\n",
        "    ax4.set_ylim([max(0, cv_scores.min() - 0.05), min(1, cv_scores.max() + 0.05)])\n",
        "\n",
        "    # Añadir línea de media\n",
        "    ax4.axhline(y=cv_scores.mean(), color='blue', linestyle='--', linewidth=2,\n",
        "               label=f'Media: {cv_scores.mean():.3f}±{cv_scores.std():.3f}')\n",
        "    ax4.legend(loc='lower right', fontsize=9)\n",
        "\n",
        "    # Añadir texto con scores individuales\n",
        "    scores_text = 'Scores: ' + ', '.join([f'{s:.3f}' for s in cv_scores])\n",
        "    ax4.text(0.5, -0.15, scores_text, transform=ax4.transAxes,\n",
        "            ha='center', fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    nombre_grafico = f'Modelo_{numero_modelo}_{nombre_archivo}.png'\n",
        "    plt.savefig(nombre_grafico, dpi=300, bbox_inches='tight')\n",
        "    print(f\"  ✓ Guardado: {nombre_grafico}\")\n",
        "    plt.close()\n",
        "\n",
        "    # =========================================================================\n",
        "    # INTERPRETACIÓN AUTOMÁTICA\n",
        "    # =========================================================================\n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(\"INTERPRETACIÓN:\")\n",
        "    print('─'*80)\n",
        "\n",
        "    # Interpretación de Accuracy\n",
        "    if accuracy >= 0.90:\n",
        "        print(f\"  • Accuracy EXCELENTE ({accuracy*100:.1f}%): El modelo es altamente confiable.\")\n",
        "    elif accuracy >= 0.80:\n",
        "        print(f\"  • Accuracy BUENA ({accuracy*100:.1f}%): El modelo tiene buen desempeño general.\")\n",
        "    elif accuracy >= 0.70:\n",
        "        print(f\"  • Accuracy ACEPTABLE ({accuracy*100:.1f}%): El modelo funciona razonablemente.\")\n",
        "    else:\n",
        "        print(f\"  • Accuracy BAJA ({accuracy*100:.1f}%): El modelo necesita mejoras.\")\n",
        "\n",
        "    # Interpretación de Precision vs Recall\n",
        "    if precision > recall + 0.05:\n",
        "        print(f\"  • ALTA PRECISION ({precision*100:.1f}%), RECALL MODERADO ({recall*100:.1f}%):\")\n",
        "        print(f\"    El modelo es conservador - pocas falsas alarmas pero pierde algunos casos.\")\n",
        "    elif recall > precision + 0.05:\n",
        "        print(f\"  • ALTO RECALL ({recall*100:.1f}%), PRECISION MODERADA ({precision*100:.1f}%):\")\n",
        "        print(f\"    El modelo es sensible - detecta la mayoría de casos pero con más falsas alarmas.\")\n",
        "    else:\n",
        "        print(f\"  • PRECISION ({precision*100:.1f}%) y RECALL ({recall*100:.1f}%) BALANCEADOS:\")\n",
        "        print(f\"    El modelo tiene equilibrio entre detectar casos y evitar falsas alarmas.\")\n",
        "\n",
        "    # Interpretación de F1-Score\n",
        "    if f1 >= 0.85:\n",
        "        print(f\"  • F1-Score EXCELENTE ({f1*100:.1f}%): Balance óptimo precision-recall.\")\n",
        "    elif f1 >= 0.75:\n",
        "        print(f\"  • F1-Score BUENO ({f1*100:.1f}%): Buen balance general.\")\n",
        "    else:\n",
        "        print(f\"  • F1-Score MEJORABLE ({f1*100:.1f}%): Revisar umbral de decisión.\")\n",
        "\n",
        "    # Interpretación de Validación Cruzada\n",
        "    cv_std = cv_scores.std()\n",
        "    if cv_std < 0.02:\n",
        "        print(f\"  • ALTA ESTABILIDAD (σ={cv_std:.4f}): Modelo muy robusto y consistente.\")\n",
        "    elif cv_std < 0.05:\n",
        "        print(f\"  • BUENA ESTABILIDAD (σ={cv_std:.4f}): Modelo confiable.\")\n",
        "    else:\n",
        "        print(f\"  • ESTABILIDAD VARIABLE (σ={cv_std:.4f}): Desempeño depende de los datos.\")\n",
        "\n",
        "    # Interpretación de ROC-AUC\n",
        "    if roc_auc:\n",
        "        if roc_auc >= 0.90:\n",
        "            print(f\"  • ROC-AUC EXCELENTE ({roc_auc*100:.1f}%): Capacidad discriminativa superior.\")\n",
        "        elif roc_auc >= 0.80:\n",
        "            print(f\"  • ROC-AUC BUENA ({roc_auc*100:.1f}%): Buena capacidad de separación de clases.\")\n",
        "        elif roc_auc >= 0.70:\n",
        "            print(f\"  • ROC-AUC ACEPTABLE ({roc_auc*100:.1f}%): Capacidad discriminativa moderada.\")\n",
        "        else:\n",
        "            print(f\"  • ROC-AUC BAJA ({roc_auc*100:.1f}%): Limitada capacidad discriminativa.\")\n",
        "\n",
        "    # Análisis de errores\n",
        "    fn = cm[1, 0]  # Falsos Negativos\n",
        "    fp = cm[0, 1]  # Falsos Positivos\n",
        "    total_errors = fn + fp\n",
        "\n",
        "    if total_errors > 0:\n",
        "        print(f\"\\n  • ANÁLISIS DE ERRORES:\")\n",
        "        print(f\"    - Falsos Negativos: {fn} ({fn/total_errors*100:.1f}% de errores)\")\n",
        "        print(f\"      → Niños que SÍ se cepillan pero predichos como NO\")\n",
        "        print(f\"    - Falsos Positivos: {fp} ({fp/total_errors*100:.1f}% de errores)\")\n",
        "        print(f\"      → Niños que NO se cepillan pero predichos como SÍ\")\n",
        "\n",
        "        if fn > fp * 1.5:\n",
        "            print(f\"    ⚠ PREDOMINAN FALSOS NEGATIVOS: Ajustar umbral para detectar más casos.\")\n",
        "        elif fp > fn * 1.5:\n",
        "            print(f\"    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\")\n",
        "\n",
        "    return {\n",
        "        'Modelo': nombre_modelo,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'CV_Mean': cv_scores.mean(),\n",
        "        'CV_Std': cv_scores.std(),\n",
        "        'CM': cm,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba,\n",
        "        'cv_scores': cv_scores\n",
        "    }\n"
      ],
      "metadata": {
        "id": "T__7kis7unbm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 7: ENTRENAMIENTO Y EVALUACIÓN DE MODELOS\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PASO 7: ENTRENAMIENTO DE LOS 7 MODELOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "resultados_todos = []\n",
        "modelos_entrenados = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfalwFOyuvNl",
        "outputId": "2f2a100a-148f-417c-d992-b308b651c7d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PASO 7: ENTRENAMIENTO DE LOS 7 MODELOS\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 1: REGRESIÓN LOGÍSTICA\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 1/7: REGRESIÓN LOGÍSTICA\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs')\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_lr = evaluar_modelo('Regresión Logística', lr, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=1)\n",
        "resultados_todos.append(resultados_lr)\n",
        "modelos_entrenados['Logistic Regression'] = lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axP2eP_ZvLk5",
        "outputId": "ba93906e-0293-4f68-a85c-f3acb2d96336"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 1/7: REGRESIÓN LOGÍSTICA\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: Regresión Logística\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.8038 (80.38%)\n",
            "  Precision:    0.8045 (80.45%)\n",
            "  Recall:       0.9984 (99.84%)\n",
            "  F1-Score:     0.8910 (89.10%)\n",
            "  ROC-AUC:      0.6605 (66.05%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.8024 ± 0.0005\n",
            "  Rango:        [0.8015, 0.8031]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[  10 1214]\n",
            " [   8 4996]]\n",
            "\n",
            "  VN:     10  |  FP:   1214\n",
            "  FN:      8  |  VP:   4996\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_1_Regresión_Logística.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy BUENA (80.4%): El modelo tiene buen desempeño general.\n",
            "  • ALTO RECALL (99.8%), PRECISION MODERADA (80.5%):\n",
            "    El modelo es sensible - detecta la mayoría de casos pero con más falsas alarmas.\n",
            "  • F1-Score EXCELENTE (89.1%): Balance óptimo precision-recall.\n",
            "  • ALTA ESTABILIDAD (σ=0.0005): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC BAJA (66.0%): Limitada capacidad discriminativa.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 8 (0.7% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 1214 (99.3% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 2: SUPPORT VECTOR CLASSIFIER\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 2/7: SUPPORT VECTOR CLASSIFIER (SVC)\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "svc = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_svc = evaluar_modelo('SVC', svc, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=2)\n",
        "resultados_todos.append(resultados_svc)\n",
        "modelos_entrenados['SVC'] = svc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jseNZ8zgwzIg",
        "outputId": "e9a0b08d-5ccc-47f6-8640-d55ce242ac13"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 2/7: SUPPORT VECTOR CLASSIFIER (SVC)\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: SVC\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.8120 (81.20%)\n",
            "  Precision:    0.8229 (82.29%)\n",
            "  Recall:       0.9760 (97.60%)\n",
            "  F1-Score:     0.8930 (89.30%)\n",
            "  ROC-AUC:      0.8231 (82.31%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.8104 ± 0.0019\n",
            "  Rango:        [0.8071, 0.8127]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[ 173 1051]\n",
            " [ 120 4884]]\n",
            "\n",
            "  VN:    173  |  FP:   1051\n",
            "  FN:    120  |  VP:   4884\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_2_SVC.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy BUENA (81.2%): El modelo tiene buen desempeño general.\n",
            "  • ALTO RECALL (97.6%), PRECISION MODERADA (82.3%):\n",
            "    El modelo es sensible - detecta la mayoría de casos pero con más falsas alarmas.\n",
            "  • F1-Score EXCELENTE (89.3%): Balance óptimo precision-recall.\n",
            "  • ALTA ESTABILIDAD (σ=0.0019): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC BUENA (82.3%): Buena capacidad de separación de clases.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 120 (10.2% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 1051 (89.8% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 3: GAUSSIAN NAIVE BAYES\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 3/7: GAUSSIAN NAIVE BAYES\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_gnb = evaluar_modelo('Gaussian Naive Bayes', gnb, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=3)\n",
        "resultados_todos.append(resultados_gnb)\n",
        "modelos_entrenados['Gaussian NB'] = gnb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuuT3pa90XXd",
        "outputId": "461dcc7f-79ad-4bcd-c1ff-1ac44c9ae6f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 3/7: GAUSSIAN NAIVE BAYES\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: Gaussian Naive Bayes\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.6551 (65.51%)\n",
            "  Precision:    0.9931 (99.31%)\n",
            "  Recall:       0.5747 (57.47%)\n",
            "  F1-Score:     0.7281 (72.81%)\n",
            "  ROC-AUC:      0.8331 (83.31%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.6584 ± 0.0011\n",
            "  Rango:        [0.6568, 0.6600]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[1204   20]\n",
            " [2128 2876]]\n",
            "\n",
            "  VN:   1204  |  FP:     20\n",
            "  FN:   2128  |  VP:   2876\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_3_Gaussian_Naive_Bayes.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy BAJA (65.5%): El modelo necesita mejoras.\n",
            "  • ALTA PRECISION (99.3%), RECALL MODERADO (57.5%):\n",
            "    El modelo es conservador - pocas falsas alarmas pero pierde algunos casos.\n",
            "  • F1-Score MEJORABLE (72.8%): Revisar umbral de decisión.\n",
            "  • ALTA ESTABILIDAD (σ=0.0011): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC BUENA (83.3%): Buena capacidad de separación de clases.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 2128 (99.1% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 20 (0.9% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS NEGATIVOS: Ajustar umbral para detectar más casos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 4: K-NEIGHBORS CLASSIFIER\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 4/7: K-NEIGHBORS CLASSIFIER\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_knn = evaluar_modelo('K-Neighbors', knn, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=4)\n",
        "resultados_todos.append(resultados_knn)\n",
        "modelos_entrenados['KNeighbors'] = knn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRoeV3Vr0kXU",
        "outputId": "0da29457-2277-44c9-d6b4-a98e9c8ba5c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 4/7: K-NEIGHBORS CLASSIFIER\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: K-Neighbors\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.7879 (78.79%)\n",
            "  Precision:    0.8491 (84.91%)\n",
            "  Recall:       0.8951 (89.51%)\n",
            "  F1-Score:     0.8715 (87.15%)\n",
            "  ROC-AUC:      0.7781 (77.81%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.7896 ± 0.0054\n",
            "  Rango:        [0.7830, 0.7979]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[ 428  796]\n",
            " [ 525 4479]]\n",
            "\n",
            "  VN:    428  |  FP:    796\n",
            "  FN:    525  |  VP:   4479\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_4_K-Neighbors.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy ACEPTABLE (78.8%): El modelo funciona razonablemente.\n",
            "  • PRECISION (84.9%) y RECALL (89.5%) BALANCEADOS:\n",
            "    El modelo tiene equilibrio entre detectar casos y evitar falsas alarmas.\n",
            "  • F1-Score EXCELENTE (87.1%): Balance óptimo precision-recall.\n",
            "  • ALTA ESTABILIDAD (σ=0.0054): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC ACEPTABLE (77.8%): Capacidad discriminativa moderada.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 525 (39.7% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 796 (60.3% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 5: RANDOM FOREST\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 5/7: RANDOM FOREST\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_rf = evaluar_modelo('Random Forest', rf, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=5)\n",
        "resultados_todos.append(resultados_rf)\n",
        "modelos_entrenados['Random Forest'] = rf\n",
        "\n",
        "print(f\"\\nImportancia de características (Top 5):\")\n",
        "importancia = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Importancia': rf.feature_importances_\n",
        "}).sort_values('Importancia', ascending=False).head()\n",
        "print(importancia.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfLQKN4o1LGH",
        "outputId": "b93992c3-6e2a-4374-8687-cef6fe3a2e41"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 5/7: RANDOM FOREST\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: Random Forest\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.8076 (80.76%)\n",
            "  Precision:    0.8332 (83.32%)\n",
            "  Recall:       0.9510 (95.10%)\n",
            "  F1-Score:     0.8882 (88.82%)\n",
            "  ROC-AUC:      0.8405 (84.05%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.8114 ± 0.0021\n",
            "  Rango:        [0.8091, 0.8147]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[ 271  953]\n",
            " [ 245 4759]]\n",
            "\n",
            "  VN:    271  |  FP:    953\n",
            "  FN:    245  |  VP:   4759\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_5_Random_Forest.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy BUENA (80.8%): El modelo tiene buen desempeño general.\n",
            "  • ALTO RECALL (95.1%), PRECISION MODERADA (83.3%):\n",
            "    El modelo es sensible - detecta la mayoría de casos pero con más falsas alarmas.\n",
            "  • F1-Score EXCELENTE (88.8%): Balance óptimo precision-recall.\n",
            "  • ALTA ESTABILIDAD (σ=0.0021): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC BUENA (84.0%): Buena capacidad de separación de clases.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 245 (20.5% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 953 (79.5% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\n",
            "\n",
            "Importancia de características (Top 5):\n",
            "    Variable  Importancia\n",
            "       QS811     0.527319\n",
            "   Pesomen12     0.224287\n",
            "      QS802D     0.088750\n",
            "quintil_peso     0.036573\n",
            "       QS803     0.028128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 6: ADABOOST\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 6/7: ADABOOST CLASSIFIER\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "ada = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
        "    n_estimators=50,\n",
        "    learning_rate=1.0,\n",
        "    random_state=42,\n",
        "    algorithm='SAMME'\n",
        ")\n",
        "ada.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_ada = evaluar_modelo('AdaBoost', ada, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=6)\n",
        "resultados_todos.append(resultados_ada)\n",
        "modelos_entrenados['AdaBoost'] = ada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSVV67CB1kFo",
        "outputId": "f265a0a2-7ea6-46bf-c492-34f9f8ce5d70"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 6/7: ADABOOST CLASSIFIER\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: AdaBoost\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.8035 (80.35%)\n",
            "  Precision:    0.8035 (80.35%)\n",
            "  Recall:       1.0000 (100.00%)\n",
            "  F1-Score:     0.8910 (89.10%)\n",
            "  ROC-AUC:      0.8124 (81.24%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.8020 ± 0.0029\n",
            "  Rango:        [0.7963, 0.8035]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[   0 1224]\n",
            " [   0 5004]]\n",
            "\n",
            "  VN:      0  |  FP:   1224\n",
            "  FN:      0  |  VP:   5004\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_6_AdaBoost.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy BUENA (80.3%): El modelo tiene buen desempeño general.\n",
            "  • ALTO RECALL (100.0%), PRECISION MODERADA (80.3%):\n",
            "    El modelo es sensible - detecta la mayoría de casos pero con más falsas alarmas.\n",
            "  • F1-Score EXCELENTE (89.1%): Balance óptimo precision-recall.\n",
            "  • ALTA ESTABILIDAD (σ=0.0029): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC BUENA (81.2%): Buena capacidad de separación de clases.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 0 (0.0% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 1224 (100.0% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------\n",
        "# MODELO 7: GRADIENT BOOSTING\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"MODELO 7/7: GRADIENT BOOSTING CLASSIFIER\")\n",
        "print(\"─\"*80)\n",
        "\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "gb.fit(X_train_scaled, y_train)\n",
        "\n",
        "resultados_gb = evaluar_modelo('Gradient Boosting', gb, X_train_scaled, X_test_scaled, y_train, y_test, numero_modelo=7)\n",
        "resultados_todos.append(resultados_gb)\n",
        "modelos_entrenados['Gradient Boosting'] = gb\n",
        "\n",
        "print(f\"\\nImportancia de características (Top 5):\")\n",
        "importancia_gb = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Importancia': gb.feature_importances_\n",
        "}).sort_values('Importancia', ascending=False).head()\n",
        "print(importancia_gb.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXKJM2ph1-iE",
        "outputId": "f4d0e1f0-8e30-4ded-c59c-92ac0b6949f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MODELO 7/7: GRADIENT BOOSTING CLASSIFIER\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: Gradient Boosting\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MÉTRICAS EN CONJUNTO DE PRUEBA:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Accuracy:     0.8115 (81.15%)\n",
            "  Precision:    0.8328 (83.28%)\n",
            "  Recall:       0.9576 (95.76%)\n",
            "  F1-Score:     0.8909 (89.09%)\n",
            "  ROC-AUC:      0.8467 (84.67%)\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "VALIDACIÓN CRUZADA (5-FOLD):\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  Media:        0.8141 ± 0.0031\n",
            "  Rango:        [0.8107, 0.8193]\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "MATRIZ DE CONFUSIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "[[ 262  962]\n",
            " [ 212 4792]]\n",
            "\n",
            "  VN:    262  |  FP:    962\n",
            "  FN:    212  |  VP:   4792\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "GENERANDO GRÁFICOS...\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  ✓ Guardado: Modelo_7_Gradient_Boosting.png\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "INTERPRETACIÓN:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "  • Accuracy BUENA (81.1%): El modelo tiene buen desempeño general.\n",
            "  • ALTO RECALL (95.8%), PRECISION MODERADA (83.3%):\n",
            "    El modelo es sensible - detecta la mayoría de casos pero con más falsas alarmas.\n",
            "  • F1-Score EXCELENTE (89.1%): Balance óptimo precision-recall.\n",
            "  • ALTA ESTABILIDAD (σ=0.0031): Modelo muy robusto y consistente.\n",
            "  • ROC-AUC BUENA (84.7%): Buena capacidad de separación de clases.\n",
            "\n",
            "  • ANÁLISIS DE ERRORES:\n",
            "    - Falsos Negativos: 212 (18.1% de errores)\n",
            "      → Niños que SÍ se cepillan pero predichos como NO\n",
            "    - Falsos Positivos: 962 (81.9% de errores)\n",
            "      → Niños que NO se cepillan pero predichos como SÍ\n",
            "    ⚠ PREDOMINAN FALSOS POSITIVOS: Ajustar umbral para ser más selectivo.\n",
            "\n",
            "Importancia de características (Top 5):\n",
            " Variable  Importancia\n",
            "    QS811     0.767614\n",
            "Pesomen12     0.100775\n",
            "   QS802D     0.066454\n",
            "    QS803     0.042077\n",
            "    QS814     0.006659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RESUMEN COMPARATIVO\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESUMEN COMPARATIVO DE TODOS LOS MODELOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados_todos)\n",
        "df_resultados_sorted = df_resultados.sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"─\"*80)\n",
        "print(\"TABLA COMPARATIVA\")\n",
        "print(\"─\"*80)\n",
        "print(df_resultados_sorted[['Modelo', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'CV_Mean']].to_string(index=False))\n",
        "\n",
        "mejor = df_resultados_sorted.iloc[0]\n",
        "print(f\"\\n{'─'*80}\")\n",
        "print(f\"🏆 MEJOR MODELO: {mejor['Modelo']}\")\n",
        "print(f\"   F1-Score: {mejor['F1-Score']:.4f} ({mejor['F1-Score']*100:.2f}%)\")\n",
        "print(\"─\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvP7qiUE2PVt",
        "outputId": "7627d05f-4d16-4b60-e333-5f630b7b7163"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RESUMEN COMPARATIVO DE TODOS LOS MODELOS\n",
            "================================================================================\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "TABLA COMPARATIVA\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "              Modelo  Accuracy  Precision   Recall  F1-Score  ROC-AUC  CV_Mean\n",
            "                 SVC  0.811978   0.822915 0.976019  0.892952 0.823081 0.810397\n",
            " Regresión Logística  0.803789   0.804509 0.998401  0.891029 0.660451 0.802369\n",
            "            AdaBoost  0.803468   0.803468 1.000000  0.891026 0.812389 0.802047\n",
            "   Gradient Boosting  0.811496   0.832812 0.957634  0.890872 0.846748 0.814091\n",
            "       Random Forest  0.807643   0.833158 0.951039  0.888205 0.840466 0.811441\n",
            "         K-Neighbors  0.787893   0.849100 0.895084  0.871486 0.778122 0.789562\n",
            "Gaussian Naive Bayes  0.655106   0.993094 0.574740  0.728101 0.833110 0.658370\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "🏆 MEJOR MODELO: SVC\n",
            "   F1-Score: 0.8930 (89.30%)\n",
            "────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# VISUALIZACIONES\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERANDO VISUALIZACIONES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Comparación de métricas\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Comparación de Métricas por Modelo', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    data_sorted = df_resultados.sort_values(metric, ascending=True)\n",
        "\n",
        "    bars = ax.barh(data_sorted['Modelo'], data_sorted[metric], color=colors[idx], alpha=0.7)\n",
        "    ax.set_xlabel(metric, fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'{metric}', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlim([0, 1])\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    for i, (v, bar) in enumerate(zip(data_sorted[metric], bars)):\n",
        "        ax.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('01_comparacion_metricas.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✓ Guardado: 01_comparacion_metricas.png\")\n",
        "plt.close()\n",
        "\n",
        "# 2. Curvas ROC\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for resultado in resultados_todos:\n",
        "    if resultado['y_pred_proba'] is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, resultado['y_pred_proba'])\n",
        "        auc = resultado['ROC-AUC']\n",
        "        ax.plot(fpr, tpr, linewidth=2, label=f\"{resultado['Modelo']} (AUC={auc:.3f})\")\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Aleatorio (AUC=0.500)')\n",
        "ax.set_xlabel('Tasa de Falsos Positivos', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Tasa de Verdaderos Positivos', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Curvas ROC', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('02_curvas_roc.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✓ Guardado: 02_curvas_roc.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx9HU7cV2VM4",
        "outputId": "b0c236de-36cc-443f-8541-2f0c92cad807"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERANDO VISUALIZACIONES\n",
            "================================================================================\n",
            "✓ Guardado: 01_comparacion_metricas.png\n",
            "✓ Guardado: 02_curvas_roc.png\n"
          ]
        }
      ]
    }
  ]
}